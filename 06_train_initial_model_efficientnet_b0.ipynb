{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"sourceType":"competition"},{"sourceId":11800527,"sourceType":"datasetVersion","datasetId":7410601},{"sourceId":11961749,"sourceType":"datasetVersion","datasetId":7521541}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport logging\nimport random\nimport gc\nimport time\nimport cv2\nimport math\nimport warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport librosa\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nimport timm\n\nwarnings.filterwarnings(\"ignore\")\nlogging.basicConfig(level=logging.ERROR)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:40:28.219813Z","iopub.execute_input":"2025-05-27T04:40:28.220168Z","iopub.status.idle":"2025-05-27T04:40:40.385536Z","shell.execute_reply.started":"2025-05-27T04:40:28.220139Z","shell.execute_reply":"2025-05-27T04:40:40.384993Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import numpy as np\n\n# Replace 'path/to/file.npy' with your actual filename\narr = np.load('/kaggle/input/mel-spec-npy-dict/mel_specs (1).npy', allow_pickle=True).item()\n\n# inspect\nprint(type(arr))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T21:32:33.497939Z","iopub.execute_input":"2025-05-26T21:32:33.499812Z","iopub.status.idle":"2025-05-26T21:33:15.457570Z","shell.execute_reply.started":"2025-05-26T21:32:33.499746Z","shell.execute_reply":"2025-05-26T21:33:15.455896Z"}},"outputs":[{"name":"stdout","text":"<class 'dict'>\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import itertools\nfor key, value in itertools.islice(arr.items(), 5):\n    print(f\"Key: {key}\")\n    print(f\"Value:\\n{value}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T21:33:40.809113Z","iopub.execute_input":"2025-05-26T21:33:40.810486Z","iopub.status.idle":"2025-05-26T21:33:40.822211Z","shell.execute_reply.started":"2025-05-26T21:33:40.810441Z","shell.execute_reply":"2025-05-26T21:33:40.820772Z"}},"outputs":[{"name":"stdout","text":"Key: 1139490/CSA36385.ogg\nValue:\n[[0.01789158 0.         0.         ... 0.5486588  0.62437123 0.6126248 ]\n [0.01626605 0.         0.         ... 0.55647945 0.62296313 0.62886786]\n [0.013015   0.         0.         ... 0.5721207  0.620147   0.6613538 ]\n ...\n [0.09885019 0.05090576 0.05342069 ... 0.37939176 0.3772261  0.49574164]\n [0.09692583 0.01696859 0.0178069  ... 0.12646392 0.12574203 0.37073165]\n [0.09596366 0.         0.         ... 0.         0.         0.30822667]]\n\nKey: 1139490/CSA36389.ogg\nValue:\n[[0.         0.         0.         ... 0.02069894 0.00536066 0.10744955]\n [0.         0.         0.         ... 0.07629509 0.04058953 0.12448078]\n [0.         0.         0.         ... 0.18748736 0.11104726 0.15854324]\n ...\n [0.         0.         0.         ... 0.5650746  0.59219754 0.70578283]\n [0.         0.         0.         ... 0.1883582  0.19739917 0.5114504 ]\n [0.         0.         0.         ... 0.         0.         0.41428423]]\n\nKey: 1192948/CSA36358.ogg\nValue:\n[[0.30032918 0.36380148 0.36165652 ... 0.6383137  0.6381418  0.6417205 ]\n [0.2666976  0.32004595 0.3062722  ... 0.5600597  0.5502577  0.564945  ]\n [0.1994344  0.23253486 0.1955036  ... 0.40355182 0.37448934 0.41139397]\n ...\n [0.         0.         0.         ... 0.19354516 0.16083787 0.21444327]\n [0.         0.         0.         ... 0.06451505 0.05361262 0.14568102]\n [0.         0.         0.         ... 0.         0.         0.11129992]]\n\nKey: 1192948/CSA36366.ogg\nValue:\n[[0.11582661 0.         0.         ... 0.         0.         0.12006897]\n [0.11181432 0.         0.         ... 0.         0.00087198 0.12760659]\n [0.10378973 0.         0.         ... 0.         0.00261595 0.14268182]\n ...\n [0.02614425 0.         0.         ... 0.22727835 0.24944544 0.35736218]\n [0.00871475 0.         0.         ... 0.07575945 0.08314848 0.24910766]\n [0.         0.         0.         ... 0.         0.         0.1949804 ]]\n\nKey: 1192948/CSA36373.ogg\nValue:\n[[0.         0.         0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.03642024 0.03593288 0.00344024]\n [0.         0.         0.         ... 0.10926071 0.10779865 0.01032072]\n ...\n [0.         0.         0.         ... 0.20356299 0.21563749 0.21049872]\n [0.         0.         0.         ... 0.06785433 0.07187916 0.07016624]\n [0.         0.         0.         ... 0.         0.         0.        ]]\n\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"class CFG:\n    \n    seed = 42\n    debug = False  \n    apex = False\n    print_freq = 100\n    num_workers = 2\n    \n    OUTPUT_DIR = '/kaggle/working/'\n\n    train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n    train_csv = '/kaggle/input/birdclef-2025/train.csv'\n    test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n    submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n    taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n\n    spectrogram_npy = '/kaggle/input/mel-spec-npy-dict/mel_specs (1).npy'\n\n    model_name = 'efficientnet_b0'\n    \n    pretrained = True\n    in_channels = 1\n\n    LOAD_DATA = True  \n    sample_rate = 32000\n    target_duration = 5.0\n    target_shape = (256, 256)\n    \n    n_fft = 1024\n    hop_length = 512\n    n_mels = 128\n    f_min = 20\n    f_max = 16000\n    \n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    epochs = 10  \n    batch_size = 32  \n    criterion = 'BCEWithLogitsLoss'\n\n    n_fold = 3\n    selected_folds = [0, 1, 2]   \n\n    optimizer = 'AdamW'\n    lr = 5e-4 \n    weight_decay = 1e-5\n  \n    scheduler = 'CosineAnnealingLR'\n    min_lr = 1e-6\n    T_max = epochs\n\n    aug_prob = 0.5  \n    mixup_alpha = 0.5  \n    \n    def update_debug_settings(self):\n        if self.debug:\n            self.epochs = 2\n            self.selected_folds = [0]\n\ncfg = CFG()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:42:26.253586Z","iopub.execute_input":"2025-05-27T04:42:26.254388Z","iopub.status.idle":"2025-05-27T04:42:26.321955Z","shell.execute_reply.started":"2025-05-27T04:42:26.254358Z","shell.execute_reply":"2025-05-27T04:42:26.321173Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_df = pd.read_csv(cfg.train_csv)\nprint(train_df.head())\nprint(\"\\nExample filename from train_df:\", train_df['filename'].iloc[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:42:29.535722Z","iopub.execute_input":"2025-05-27T04:42:29.536042Z","iopub.status.idle":"2025-05-27T04:42:29.708024Z","shell.execute_reply.started":"2025-05-27T04:42:29.536018Z","shell.execute_reply":"2025-05-27T04:42:29.707253Z"}},"outputs":[{"name":"stdout","text":"  primary_label secondary_labels  type              filename collection  \\\n0       1139490             ['']  ['']  1139490/CSA36385.ogg        CSA   \n1       1139490             ['']  ['']  1139490/CSA36389.ogg        CSA   \n2       1192948             ['']  ['']  1192948/CSA36358.ogg        CSA   \n3       1192948             ['']  ['']  1192948/CSA36366.ogg        CSA   \n4       1192948             ['']  ['']  1192948/CSA36373.ogg        CSA   \n\n   rating                                                url  latitude  \\\n0     0.0  http://colecciones.humboldt.org.co/rec/sonidos...    7.3206   \n1     0.0  http://colecciones.humboldt.org.co/rec/sonidos...    7.3206   \n2     0.0  http://colecciones.humboldt.org.co/rec/sonidos...    7.3791   \n3     0.0  http://colecciones.humboldt.org.co/rec/sonidos...    7.2800   \n4     0.0  http://colecciones.humboldt.org.co/rec/sonidos...    7.3791   \n\n   longitude        scientific_name            common_name             author  \\\n0   -73.7128   Ragoniella pulchella   Ragoniella pulchella  Fabio A. Sarria-S   \n1   -73.7128   Ragoniella pulchella   Ragoniella pulchella  Fabio A. Sarria-S   \n2   -73.7313  Oxyprora surinamensis  Oxyprora surinamensis  Fabio A. Sarria-S   \n3   -73.8582  Oxyprora surinamensis  Oxyprora surinamensis  Fabio A. Sarria-S   \n4   -73.7313  Oxyprora surinamensis  Oxyprora surinamensis  Fabio A. Sarria-S   \n\n           license  \n0  cc-by-nc-sa 4.0  \n1  cc-by-nc-sa 4.0  \n2  cc-by-nc-sa 4.0  \n3  cc-by-nc-sa 4.0  \n4  cc-by-nc-sa 4.0  \n\nExample filename from train_df: 1139490/CSA36385.ogg\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def set_seed(seed=42):\n    \"\"\"\n    Set seed for reproducibility\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(cfg.seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:42:32.797547Z","iopub.execute_input":"2025-05-27T04:42:32.798217Z","iopub.status.idle":"2025-05-27T04:42:32.810288Z","shell.execute_reply.started":"2025-05-27T04:42:32.798187Z","shell.execute_reply":"2025-05-27T04:42:32.809612Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class BirdCLEFDatasetFromNPY(Dataset):\n    def __init__(self, df, cfg, spectrograms=None, mode=\"train\"):\n        self.df = df\n        self.cfg = cfg\n        self.mode = mode\n\n        self.spectrograms = spectrograms\n        \n        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n        self.species_ids = taxonomy_df['primary_label'].tolist()\n        self.num_classes = len(self.species_ids)\n        self.label_to_idx = {label: idx for idx, label in enumerate(self.species_ids)}\n\n        if 'filepath' not in self.df.columns:\n            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n        \n        if 'samplename' not in self.df.columns:\n            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n\n        filenames_set = set(self.df['filename']) # Use 'filename'\n        if self.spectrograms:\n            found_samples = sum(1 for name in filenames_set if name in self.spectrograms) # Compare filename to keys\n            print(f\"Found {found_samples} matching spectrograms for {mode} dataset out of {len(self.df)} samples\")\n        \n        if cfg.debug:\n            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n    \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n       \n        filename = row['filename'] \n        spec = None\n\n        # --- CHANGE: Use 'filename' as the key ---\n        if self.spectrograms and filename in self.spectrograms:\n            spec = self.spectrograms[filename]\n        elif not self.cfg.LOAD_DATA:\n            # This part will likely not run, but keep it as a fallback\n            spec = process_audio_file(row['filepath'], self.cfg)\n\n        if spec is None:\n            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n            if self.mode == \"train\": \n                print(f\"Warning: Spectrogram for {filename} not found and could not be generated\")\n\n        spec = torch.tensor(spec, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n\n        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n            spec = self.apply_spec_augmentations(spec)\n        \n        target = self.encode_label(row['primary_label'])\n        \n        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n            if isinstance(row['secondary_labels'], str):\n                secondary_labels = eval(row['secondary_labels'])\n            else:\n                secondary_labels = row['secondary_labels']\n            \n            for label in secondary_labels:\n                if label in self.label_to_idx:\n                    target[self.label_to_idx[label]] = 1.0\n        \n        return {\n            'melspec': spec, \n            'target': torch.tensor(target, dtype=torch.float32),\n            'filename': row['filename']\n        }\n\n    def apply_spec_augmentations(self, spec):\n        # This function remains the same\n        if random.random() < 0.5:\n            num_masks = random.randint(1, 3)\n            for _ in range(num_masks):\n                width = random.randint(5, 20)\n                start = random.randint(0, spec.shape[2] - width)\n                spec[0, :, start:start+width] = 0\n        \n        if random.random() < 0.5:\n            num_masks = random.randint(1, 3)\n            for _ in range(num_masks):\n                height = random.randint(5, 20)\n                start = random.randint(0, spec.shape[1] - height)\n                spec[0, start:start+height, :] = 0\n        \n        if random.random() < 0.5:\n            gain = random.uniform(0.8, 1.2)\n            bias = random.uniform(-0.1, 0.1)\n            spec = spec * gain + bias\n            spec = torch.clamp(spec, 0, 1) \n            \n        return spec\n    \n    def encode_label(self, label):\n        # This function remains the same\n        target = np.zeros(self.num_classes)\n        if label in self.label_to_idx:\n            target[self.label_to_idx[label]] = 1.0\n        return target\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:42:33.873584Z","iopub.execute_input":"2025-05-27T04:42:33.874287Z","iopub.status.idle":"2025-05-27T04:42:33.889120Z","shell.execute_reply.started":"2025-05-27T04:42:33.874260Z","shell.execute_reply":"2025-05-27T04:42:33.888317Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def collate_fn(batch):\n    \"\"\"Custom collate function to handle different sized spectrograms\"\"\"\n    batch = [item for item in batch if item is not None]\n    if len(batch) == 0:\n        return {}\n        \n    result = {key: [] for key in batch[0].keys()}\n    \n    for item in batch:\n        for key, value in item.items():\n            result[key].append(value)\n    \n    for key in result:\n        if key == 'target' and isinstance(result[key][0], torch.Tensor):\n            result[key] = torch.stack(result[key])\n        elif key == 'melspec' and isinstance(result[key][0], torch.Tensor):\n            shapes = [t.shape for t in result[key]]\n            if len(set(str(s) for s in shapes)) == 1:\n                result[key] = torch.stack(result[key])\n    \n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:42:36.700085Z","iopub.execute_input":"2025-05-27T04:42:36.700371Z","iopub.status.idle":"2025-05-27T04:42:36.706389Z","shell.execute_reply.started":"2025-05-27T04:42:36.700351Z","shell.execute_reply":"2025-05-27T04:42:36.705750Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class BirdCLEFModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        \n        taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n        cfg.num_classes = len(taxonomy_df)\n        \n        self.backbone = timm.create_model(\n            cfg.model_name,\n            pretrained=cfg.pretrained,\n            in_chans=cfg.in_channels,\n            drop_rate=0.2,\n            drop_path_rate=0.2\n        )\n\n        if 'efficientnet' in cfg.model_name:\n                backbone_out = self.backbone.classifier.in_features\n                self.backbone.classifier = nn.Identity()\n        elif 'resnet' in cfg.model_name:\n            backbone_out = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        else:\n            backbone_out = self.backbone.get_classifier().in_features\n            self.backbone.reset_classifier(0, '')\n        \n        self.pooling = nn.AdaptiveAvgPool2d(1)\n            \n        self.feat_dim = backbone_out\n        \n        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n        \n        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n        if self.mixup_enabled:\n            self.mixup_alpha = cfg.mixup_alpha\n\n    def forward(self, x, targets=None):\n        if self.training and self.mixup_enabled and targets is not None:\n            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n            x = mixed_x\n        else:\n            targets_a, targets_b, lam = None, None, None\n        \n        features = self.backbone(x)\n        \n        if isinstance(features, dict):\n            features = features['features']\n            \n        if len(features.shape) == 4:\n            features = self.pooling(features)\n            features = features.view(features.size(0), -1)\n        \n        logits = self.classifier(features)\n        \n        if self.training and self.mixup_enabled and targets is not None:\n            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, \n                                       logits, targets_a, targets_b, lam)\n            return logits, loss\n            \n        return logits\n\n    def mixup_data(self, x, targets):\n        \"\"\"Applies mixup to the data batch\"\"\"\n        batch_size = x.size(0)\n\n        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n\n        indices = torch.randperm(batch_size).to(x.device)\n\n        mixed_x = lam * x + (1 - lam) * x[indices]\n        \n        return mixed_x, targets, targets[indices], lam\n    \n    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n        \"\"\"Applies mixup to the loss function\"\"\"\n        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:42:38.020033Z","iopub.execute_input":"2025-05-27T04:42:38.020308Z","iopub.status.idle":"2025-05-27T04:42:38.029844Z","shell.execute_reply.started":"2025-05-27T04:42:38.020290Z","shell.execute_reply":"2025-05-27T04:42:38.029100Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def get_optimizer(model, cfg):\n  \n    if cfg.optimizer == 'Adam':\n        optimizer = optim.Adam(\n            model.parameters(),\n            lr=cfg.lr,\n            weight_decay=cfg.weight_decay\n        )\n    elif cfg.optimizer == 'AdamW':\n        optimizer = optim.AdamW(\n            model.parameters(),\n            lr=cfg.lr,\n            weight_decay=cfg.weight_decay\n        )\n    elif cfg.optimizer == 'SGD':\n        optimizer = optim.SGD(\n            model.parameters(),\n            lr=cfg.lr,\n            momentum=0.9,\n            weight_decay=cfg.weight_decay\n        )\n    else:\n        raise NotImplementedError(f\"Optimizer {cfg.optimizer} not implemented\")\n        \n    return optimizer\n\ndef get_scheduler(optimizer, cfg):\n   \n    if cfg.scheduler == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(\n            optimizer,\n            T_max=cfg.T_max,\n            eta_min=cfg.min_lr\n        )\n    elif cfg.scheduler == 'ReduceLROnPlateau':\n        scheduler = lr_scheduler.ReduceLROnPlateau(\n            optimizer,\n            mode='min',\n            factor=0.5,\n            patience=2,\n            min_lr=cfg.min_lr,\n            verbose=True\n        )\n    elif cfg.scheduler == 'StepLR':\n        scheduler = lr_scheduler.StepLR(\n            optimizer,\n            step_size=cfg.epochs // 3,\n            gamma=0.5\n        )\n    elif cfg.scheduler == 'OneCycleLR':\n        scheduler = None  \n    else:\n        scheduler = None\n        \n    return scheduler\n\ndef get_criterion(cfg):\n \n    if cfg.criterion == 'BCEWithLogitsLoss':\n        criterion = nn.BCEWithLogitsLoss()\n    else:\n        raise NotImplementedError(f\"Criterion {cfg.criterion} not implemented\")\n        \n    return criterion","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:42:40.899648Z","iopub.execute_input":"2025-05-27T04:42:40.900206Z","iopub.status.idle":"2025-05-27T04:42:40.906898Z","shell.execute_reply.started":"2025-05-27T04:42:40.900185Z","shell.execute_reply":"2025-05-27T04:42:40.906348Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, criterion, device, scheduler=None):\n    \n    model.train()\n    losses = []\n    all_targets = []\n    all_outputs = []\n    \n    pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n    \n    for step, batch in pbar:\n    \n        if isinstance(batch['melspec'], list):\n            batch_outputs = []\n            batch_losses = []\n            \n            for i in range(len(batch['melspec'])):\n                inputs = batch['melspec'][i].unsqueeze(0).to(device)\n                target = batch['target'][i].unsqueeze(0).to(device)\n                \n                optimizer.zero_grad()\n                output = model(inputs)\n                loss = criterion(output, target)\n                loss.backward()\n\n                batch_outputs.append(output.detach().cpu())\n                batch_losses.append(loss.item())\n\n            optimizer.step()\n            outputs = torch.cat(batch_outputs, dim=0).numpy()\n            loss = np.mean(batch_losses)\n            targets = batch['target'].numpy()\n        else:\n            inputs = batch['melspec'].to(device)\n            targets = batch['target'].to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            \n            if isinstance(outputs, tuple):\n                outputs, loss = outputs  \n            else:\n                loss = criterion(outputs, targets)\n                \n            loss.backward()\n            optimizer.step()\n            \n            outputs = outputs.detach().cpu().numpy()\n            targets = targets.detach().cpu().numpy()\n\n        if scheduler is not None and isinstance(scheduler, lr_scheduler.OneCycleLR):\n            scheduler.step()\n            \n        all_outputs.append(outputs)\n        all_targets.append(targets)\n        losses.append(loss if isinstance(loss, float) else loss.item())\n        \n        pbar.set_postfix({\n            'train_loss': np.mean(losses[-10:]) if losses else 0,\n            'lr': optimizer.param_groups[0]['lr']\n        })\n    \n    all_outputs = np.concatenate(all_outputs)\n    all_targets = np.concatenate(all_targets)\n    auc = calculate_auc(all_targets, all_outputs)\n    avg_loss = np.mean(losses)\n    \n    return avg_loss, auc\n            \ndef validate(model, loader, criterion, device):\n   \n    model.eval()\n    losses = []\n    all_targets = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Validation\"):\n            if isinstance(batch['melspec'], list):\n                batch_outputs = []\n                batch_losses = []\n                \n                for i in range(len(batch['melspec'])):\n                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n                    target = batch['target'][i].unsqueeze(0).to(device)\n                    \n                    output = model(inputs)\n                    loss = criterion(output, target)\n                    \n                    batch_outputs.append(output.detach().cpu())\n                    batch_losses.append(loss.item())\n\n                outputs = torch.cat(batch_outputs, dim=0).numpy()\n                loss = np.mean(batch_losses)\n                targets = batch['target'].numpy()\n            else:\n                inputs = batch['melspec'].to(device)\n                targets = batch['target'].to(device)\n                \n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                \n                outputs = outputs.detach().cpu().numpy()\n                targets = targets.detach().cpu().numpy()\n            \n            all_outputs.append(outputs)\n            all_targets.append(targets)\n            losses.append(loss if isinstance(loss, float) else loss.item())\n\n    all_outputs = np.concatenate(all_outputs)\n    all_targets = np.concatenate(all_targets)\n    \n    auc = calculate_auc(all_targets, all_outputs)\n    avg_loss = np.mean(losses)\n    \n    return avg_loss, auc\n\ndef calculate_auc(targets, outputs):\n  \n    num_classes = targets.shape[1]\n    aucs = []\n    \n    probs = 1 / (1 + np.exp(-outputs))\n    \n    for i in range(num_classes):\n        \n        if np.sum(targets[:, i]) > 0:\n            class_auc = roc_auc_score(targets[:, i], probs[:, i])\n            aucs.append(class_auc)\n    \n    return np.mean(aucs) if aucs else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:42:42.542272Z","iopub.execute_input":"2025-05-27T04:42:42.542737Z","iopub.status.idle":"2025-05-27T04:42:42.555999Z","shell.execute_reply.started":"2025-05-27T04:42:42.542714Z","shell.execute_reply":"2025-05-27T04:42:42.555295Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def run_training(df, cfg):\n    \"\"\"Training function that can either use pre-computed spectrograms or generate them on-the-fly\"\"\"\n\n    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n    species_ids = taxonomy_df['primary_label'].tolist()\n    cfg.num_classes = len(species_ids)\n    \n    if cfg.debug:\n        cfg.update_debug_settings()\n\n    spectrograms = None\n    if cfg.LOAD_DATA:\n        print(\"Loading pre-computed mel spectrograms from NPY file...\")\n        try:\n            spectrograms = np.load(cfg.spectrogram_npy, allow_pickle=True).item()\n            print(f\"Loaded {len(spectrograms)} pre-computed mel spectrograms\")\n        except Exception as e:\n            print(f\"Error loading pre-computed spectrograms: {e}\")\n            print(\"Will generate spectrograms on-the-fly instead.\")\n            cfg.LOAD_DATA = False\n    skf = StratifiedKFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\n\n    best_scores = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['primary_label'])):\n        if fold not in cfg.selected_folds:\n            continue\n            \n        print(f'\\n{\"=\"*30} Fold {fold} {\"=\"*30}')\n        \n        train_df = df.iloc[train_idx].reset_index(drop=True)\n        val_df = df.iloc[val_idx].reset_index(drop=True)\n        \n        print(f'Training set: {len(train_df)} samples')\n        print(f'Validation set: {len(val_df)} samples')\n        \n        train_dataset = BirdCLEFDatasetFromNPY(train_df, cfg, spectrograms=spectrograms, mode='train')\n        val_dataset = BirdCLEFDatasetFromNPY(val_df, cfg, spectrograms=spectrograms, mode='valid')\n\n        train_loader = DataLoader(\n            train_dataset, \n            batch_size=cfg.batch_size, \n            shuffle=True, \n            num_workers=cfg.num_workers,\n            pin_memory=True,\n            collate_fn=collate_fn,\n            drop_last=True\n        )\n        \n        val_loader = DataLoader(\n            val_dataset, \n            batch_size=cfg.batch_size, \n            shuffle=False, \n            num_workers=cfg.num_workers,\n            pin_memory=True,\n            collate_fn=collate_fn\n        )\n\n        model = BirdCLEFModel(cfg).to(cfg.device)\n        optimizer = get_optimizer(model, cfg)\n        criterion = get_criterion(cfg)\n        \n        if cfg.scheduler == 'OneCycleLR':\n            scheduler = lr_scheduler.OneCycleLR(\n                optimizer,\n                max_lr=cfg.lr,\n                steps_per_epoch=len(train_loader),\n                epochs=cfg.epochs,\n                pct_start=0.1\n            )\n        else:\n            scheduler = get_scheduler(optimizer, cfg)\n        \n        best_auc = 0\n        best_epoch = 0\n\n        for epoch in range(cfg.epochs):\n            print(f\"\\nEpoch {epoch+1}/{cfg.epochs}\")\n            \n            train_loss, train_auc = train_one_epoch(\n                model, \n                train_loader, \n                optimizer, \n                criterion, \n                cfg.device,\n                scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None\n            )\n            \n            val_loss, val_auc = validate(model, val_loader, criterion, cfg.device)\n\n            if scheduler is not None and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n                if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n                    scheduler.step(val_loss)\n                else:\n                    scheduler.step()\n\n            print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}\")\n            print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}\")\n\n            if val_auc > best_auc:\n                best_auc = val_auc\n                best_epoch = epoch + 1\n                print(f\"New best AUC: {best_auc:.4f} at epoch {best_epoch}\")\n\n                torch.save({\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n                    'epoch': epoch,\n                    'val_auc': val_auc,\n                    'train_auc': train_auc,\n                    'cfg': cfg\n                }, f\"model_fold{fold}.pth\")\n\n        best_scores.append(best_auc)\n        print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n        \n        # Clear memory\n        del model, optimizer, scheduler, train_loader, val_loader\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"Cross-Validation Results:\")\n    for fold, score in enumerate(best_scores):\n        print(f\"Fold {cfg.selected_folds[fold]}: {score:.4f}\")\n    print(f\"Mean AUC: {np.mean(best_scores):.4f}\")\n    print(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:42:50.071684Z","iopub.execute_input":"2025-05-27T04:42:50.072288Z","iopub.status.idle":"2025-05-27T04:42:50.084228Z","shell.execute_reply.started":"2025-05-27T04:42:50.072266Z","shell.execute_reply":"2025-05-27T04:42:50.083338Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    import time\n    \n    print(\"\\nLoading training data...\")\n    train_df = pd.read_csv(cfg.train_csv)\n    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n\n    print(\"\\nStarting training...\")\n    print(f\"LOAD_DATA is set to {cfg.LOAD_DATA}\")\n    if cfg.LOAD_DATA:\n        print(\"Using pre-computed mel spectrograms from NPY file\")\n    else:\n        print(\"Will generate spectrograms on-the-fly during training\")\n    \n    run_training(train_df, cfg)\n    \n    print(\"\\nTraining complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T04:43:00.797652Z","iopub.execute_input":"2025-05-27T04:43:00.798210Z","execution_failed":"2025-05-27T05:42:36.334Z"}},"outputs":[{"name":"stdout","text":"\nLoading training data...\n\nStarting training...\nLOAD_DATA is set to True\nUsing pre-computed mel spectrograms from NPY file\nLoading pre-computed mel spectrograms from NPY file...\nLoaded 28564 pre-computed mel spectrograms\n\n============================== Fold 0 ==============================\nTraining set: 19042 samples\nValidation set: 9522 samples\nFound 19042 matching spectrograms for train dataset out of 19042 samples\nFound 9522 matching spectrograms for valid dataset out of 9522 samples\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4a764a908a4e1293ae99dd77cfefea"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"698c104352da4ac8bb253042f42410b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58a6459031bb49adb956e55ab5008307"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0390, Train AUC: 0.5566\nVal Loss: 0.0267, Val AUC: 0.7895\nNew best AUC: 0.7895 at epoch 1\n\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15c668d607e8476f942e8a1408e1aea2"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7960af65d580>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2ebcb3f3190409cb690e55e8e272b3d"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0236, Train AUC: 0.8132\nVal Loss: 0.0193, Val AUC: 0.9122\nNew best AUC: 0.9122 at epoch 2\n\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87785e3f3173418ba8fae362b5a22b0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb875ce2d93a4f6dbe154f894200047b"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0184, Train AUC: 0.9152\nVal Loss: 0.0161, Val AUC: 0.9395\nNew best AUC: 0.9395 at epoch 3\n\nEpoch 4/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7f81d0dcf46403085a7ef1c95283317"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bafb925fe3d40bb9b1fd67671434569"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0153, Train AUC: 0.9481\nVal Loss: 0.0147, Val AUC: 0.9472\nNew best AUC: 0.9472 at epoch 4\n\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c5969059b4844beacd2333fa58839bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55f56b77785645528d43a02b377a4d48"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0129, Train AUC: 0.9661\nVal Loss: 0.0140, Val AUC: 0.9519\nNew best AUC: 0.9519 at epoch 5\n\nEpoch 6/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc658f7570cd4c339842ef4204302383"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ddb6856fff0406f96247754e1d8e067"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0107, Train AUC: 0.9816\nVal Loss: 0.0132, Val AUC: 0.9574\nNew best AUC: 0.9574 at epoch 6\n\nEpoch 7/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f8082a2acf541fab48f40dfa0676380"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff8bd7b389a4eaa8890429292b0c632"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0089, Train AUC: 0.9897\nVal Loss: 0.0132, Val AUC: 0.9575\nNew best AUC: 0.9575 at epoch 7\n\nEpoch 8/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45423e06eb604d2b84e736b3ac89fec1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0597458d05d549c3aff585defacfc56f"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0074, Train AUC: 0.9936\nVal Loss: 0.0133, Val AUC: 0.9575\n\nEpoch 9/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8085bae697245f1af880ff521b9cf05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36056e3be5df40d48ba5fa986d8efd1a"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0064, Train AUC: 0.9956\nVal Loss: 0.0132, Val AUC: 0.9575\n\nEpoch 10/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2475793cf5374237b5c164ddaeebc698"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c2cdf342bed4641a37c56ae7a5206f7"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0059, Train AUC: 0.9966\nVal Loss: 0.0132, Val AUC: 0.9582\nNew best AUC: 0.9582 at epoch 10\n\nBest AUC for fold 0: 0.9582 at epoch 10\n\n============================== Fold 1 ==============================\nTraining set: 19043 samples\nValidation set: 9521 samples\nFound 19043 matching spectrograms for train dataset out of 19043 samples\nFound 9521 matching spectrograms for valid dataset out of 9521 samples\n\nEpoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a4bc00acfb04f29a3fde238e89b6856"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d58b8eefc74ee9a76de2976eab9297"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0374, Train AUC: 0.5905\nVal Loss: 0.0248, Val AUC: 0.8289\nNew best AUC: 0.8289 at epoch 1\n\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"574fa00fda524b99ae5a99deaf4fdce2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcf090a039d44440a48620f739b4152c"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0225, Train AUC: 0.8391\nVal Loss: 0.0187, Val AUC: 0.9117\nNew best AUC: 0.9117 at epoch 2\n\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f8b9422b0664a77aaed3e2f9dda181f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfa68ae0564d41c78af6ae4692bb272b"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0151, Train AUC: 0.9442\nVal Loss: 0.0148, Val AUC: 0.9505\nNew best AUC: 0.9505 at epoch 4\n\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bc780c55eeb43c88c925b27312665ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b2f7910b7004b5f81ee5ca5a9ec8933"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0129, Train AUC: 0.9667\nVal Loss: 0.0142, Val AUC: 0.9556\nNew best AUC: 0.9556 at epoch 5\n\nEpoch 6/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"650c4ebc8c8046ecbca5d184c2a174c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47156c08c6474b7ca04adcd90fba358c"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0110, Train AUC: 0.9788\nVal Loss: 0.0136, Val AUC: 0.9583\nNew best AUC: 0.9583 at epoch 6\n\nEpoch 7/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99022e391fb64ac382bf9bda2f067bb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"907f45c22e9b44be828f3f21c95ba95e"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0091, Train AUC: 0.9887\nVal Loss: 0.0134, Val AUC: 0.9615\nNew best AUC: 0.9615 at epoch 7\n\nEpoch 8/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1c2ece480354010a15499c566342eb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"950d72dda5374d4ba7ad33a8a82a11e9"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0076, Train AUC: 0.9930\nVal Loss: 0.0133, Val AUC: 0.9610\n\nEpoch 9/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8cc42bce2204d7f94de863ddd9a7501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee86f5fb75ef45d29befe61cc5dbbeb4"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0066, Train AUC: 0.9953\nVal Loss: 0.0134, Val AUC: 0.9609\n\nEpoch 10/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6683b281fee849828c13ae77057bdefc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"587309565b0c462fa0f414d78e319504"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0061, Train AUC: 0.9962\nVal Loss: 0.0134, Val AUC: 0.9604\n\nBest AUC for fold 1: 0.9615 at epoch 7\n\n============================== Fold 2 ==============================\nTraining set: 19043 samples\nValidation set: 9521 samples\nFound 19043 matching spectrograms for train dataset out of 19043 samples\nFound 9521 matching spectrograms for valid dataset out of 9521 samples\n\nEpoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2468003943b84020b2bf99b217e4eb2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab09ee94b36940ffb430125e0d0d3fb2"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0385, Train AUC: 0.5368\nVal Loss: 0.0273, Val AUC: 0.7849\nNew best AUC: 0.7849 at epoch 1\n\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89928198d0f74a129cfa7cdd9c308310"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a17ef60e2148818fa72c3baf0cb237"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0241, Train AUC: 0.8123\nVal Loss: 0.0202, Val AUC: 0.8902\nNew best AUC: 0.8902 at epoch 2\n\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4738bba802b4a218f48b6aeb7f24ac3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e6c1ca7d4b42da8929662c7e245300"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0192, Train AUC: 0.8968\nVal Loss: 0.0171, Val AUC: 0.9310\nNew best AUC: 0.9310 at epoch 3\n\nEpoch 4/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b819c62e1c504fd3a8284ee4a91b6d57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf7c435d78bf46859502018f6cd1462a"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0161, Train AUC: 0.9383\nVal Loss: 0.0154, Val AUC: 0.9423\nNew best AUC: 0.9423 at epoch 4\n\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96c1dd6dcf7e4ae4a0ad24f426b7b011"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd4566b398624a7183460f4c5c86d082"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0137, Train AUC: 0.9610\nVal Loss: 0.0146, Val AUC: 0.9482\nNew best AUC: 0.9482 at epoch 5\n\nEpoch 6/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fb6dc7923ec47728d53570a39f80385"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"486dade5089e4bd29eb20eb57d0ef3c7"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0116, Train AUC: 0.9763\nVal Loss: 0.0138, Val AUC: 0.9573\nNew best AUC: 0.9573 at epoch 6\n\nEpoch 7/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"365139ccaf904201a216f9e052c4bfe7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a1b7d34683b4c07a413e6f1b27b9bfa"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0099, Train AUC: 0.9862\nVal Loss: 0.0134, Val AUC: 0.9584\nNew best AUC: 0.9584 at epoch 7\n\nEpoch 8/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45fe2c4dfba44bbbb248460bdf1e6034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90e1d194cb65493b8fc64130151236df"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0083, Train AUC: 0.9912\nVal Loss: 0.0134, Val AUC: 0.9570\n\nEpoch 9/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ea8e70c36034fc09a12778f5e2b584a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/298 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57dc6b015a2e4fff80653350ec020e81"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 0.0073, Train AUC: 0.9940\nVal Loss: 0.0134, Val AUC: 0.9584\n\nEpoch 10/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/595 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30de27594fe44bfeae043e3add272a3a"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
